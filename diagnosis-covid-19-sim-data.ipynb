{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8a2c4d04-fb40-417f-9314-5f5f9fbfc934",
   "metadata": {},
   "source": [
    "## Build a contact network"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "63bb5bf8-2f4a-4500-997f-6412fcc63150",
   "metadata": {},
   "source": [
    "# Download dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99dfcc92-af01-4ff8-a1b6-4a969b5ca943",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!wget https://lp-prod-resources.s3.amazonaws.com/628/66549/2021-06-25-19-30-14/PeopleLocations.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e4d49c0e-bbe2-4101-841f-5e797258004d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import datetime as dt\n",
    "from sklearn import preprocessing\n",
    "from geopy.distance import geodesic "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "942af55c-95a0-46e7-b8a7-a60cb4c68bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in csv to pd.DataFrame\n",
    "df = pd.read_csv(\"PeopleLocations.csv\", sep = \";\", \n",
    "                dtype={'id': np.str_, 'Lat': np.float32, 'Lon': np.float32})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "22c2c5eb-01d2-4e22-a0e7-7c718353731c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert type to category\n",
    "df[\"Covid19\"] = df[\"Covid19\"].astype(\"category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec13d5e3-beb7-4f2f-b914-f9a9b051a223",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID           object\n",
       "Lat         float32\n",
       "Lon         float32\n",
       "Date         object\n",
       "Time         object\n",
       "Covid19    category\n",
       "dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the dtypes\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fca0548e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename the first column \n",
    "df.rename(columns={\"ID\": \"IDcol\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0eecb840",
   "metadata": {},
   "outputs": [],
   "source": [
    "# store the header of the first colum of dataframe df in variable \"IDcol\"\n",
    "IDcol = df.columns[0]\n",
    "\n",
    "# determine a list of different individuals for which there is at least one record in the csv file\n",
    "uniquepart = df[IDcol].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "628384f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IDcol</th>\n",
       "      <th>Lat</th>\n",
       "      <th>Lon</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>Covid19</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Person1</td>\n",
       "      <td>60.185390</td>\n",
       "      <td>25.009689</td>\n",
       "      <td>09-06-2021</td>\n",
       "      <td>13:52:09</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Person2</td>\n",
       "      <td>60.185387</td>\n",
       "      <td>25.009678</td>\n",
       "      <td>09-06-2021</td>\n",
       "      <td>13:52:09</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Person3</td>\n",
       "      <td>60.185390</td>\n",
       "      <td>25.009695</td>\n",
       "      <td>09-06-2021</td>\n",
       "      <td>13:52:09</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Person4</td>\n",
       "      <td>60.185390</td>\n",
       "      <td>25.009689</td>\n",
       "      <td>09-06-2021</td>\n",
       "      <td>13:52:09</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Person5</td>\n",
       "      <td>60.185387</td>\n",
       "      <td>25.009672</td>\n",
       "      <td>09-06-2021</td>\n",
       "      <td>13:52:09</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Person6</td>\n",
       "      <td>60.185394</td>\n",
       "      <td>25.009706</td>\n",
       "      <td>09-06-2021</td>\n",
       "      <td>13:52:09</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Person7</td>\n",
       "      <td>60.185383</td>\n",
       "      <td>25.009668</td>\n",
       "      <td>09-06-2021</td>\n",
       "      <td>13:52:09</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Person8</td>\n",
       "      <td>60.185387</td>\n",
       "      <td>25.009686</td>\n",
       "      <td>09-06-2021</td>\n",
       "      <td>13:52:09</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Person9</td>\n",
       "      <td>60.185379</td>\n",
       "      <td>25.009634</td>\n",
       "      <td>09-06-2021</td>\n",
       "      <td>13:52:09</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Person10</td>\n",
       "      <td>60.185387</td>\n",
       "      <td>25.009678</td>\n",
       "      <td>09-06-2021</td>\n",
       "      <td>13:52:09</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      IDcol        Lat        Lon        Date      Time Covid19\n",
       "0   Person1  60.185390  25.009689  09-06-2021  13:52:09       n\n",
       "1   Person2  60.185387  25.009678  09-06-2021  13:52:09       n\n",
       "2   Person3  60.185390  25.009695  09-06-2021  13:52:09       n\n",
       "3   Person4  60.185390  25.009689  09-06-2021  13:52:09       y\n",
       "4   Person5  60.185387  25.009672  09-06-2021  13:52:09       n\n",
       "5   Person6  60.185394  25.009706  09-06-2021  13:52:09       n\n",
       "6   Person7  60.185383  25.009668  09-06-2021  13:52:09       y\n",
       "7   Person8  60.185387  25.009686  09-06-2021  13:52:09       n\n",
       "8   Person9  60.185379  25.009634  09-06-2021  13:52:09       n\n",
       "9  Person10  60.185387  25.009678  09-06-2021  13:52:09       n"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a bit of the data\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "37182a0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'They are no duplicates in the dataset. However, 300 is the number of nodes.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# determine a list of different individuals for which there is at least one record in the csv file \n",
    "dups = df[df.IDcol.duplicated()]\n",
    "\n",
    "# count the number of different individuals. this will be the number of nodes in the contace network \n",
    "no_of_nodes = df.shape[0]\n",
    "\n",
    "\n",
    "f\"They are no duplicates in the dataset. However, {no_of_nodes} is the number of nodes.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4e20068d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Covid19</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Covid19\n",
       "0         n\n",
       "1         n\n",
       "2         n\n",
       "3         y\n",
       "4         n\n",
       "..      ...\n",
       "295       n\n",
       "296       y\n",
       "297       y\n",
       "298       y\n",
       "299       n\n",
       "\n",
       "[300 rows x 1 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# before transformation\n",
    "df[[\"Covid19\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7d93307f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing the dataframe: Covid19 column \n",
    "# 0 = no covid19, 1 = covid19 using sklearn.preprocessing.LabelEncoder \n",
    "# use apply() to apply the LabelEncoder to the Covid19 column\n",
    "le = preprocessing.LabelEncoder()\n",
    "df[\"Covid19\"] = df[[\"Covid19\"]].apply(le.fit_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2269d837",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Covid19</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Covid19\n",
       "0          0\n",
       "1          0\n",
       "2          0\n",
       "3          1\n",
       "4          0\n",
       "..       ...\n",
       "295        0\n",
       "296        1\n",
       "297        1\n",
       "298        1\n",
       "299        0\n",
       "\n",
       "[300 rows x 1 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# after transformation\n",
    "df[[\"Covid19\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "22ee480c",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_of_nodes = df.shape[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "08efc6a0",
   "metadata": {},
   "source": [
    "To build the contact network we add an edge between nodes representing individuals for which we can find location recording which are closer than 2 meters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98fd7767",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create networkx object `G` by adding nodes for each individual with a record in \"PeopleLocations.csv\"\n",
    "\n",
    "G = nx.Graph()\n",
    "\n",
    "# we use a label encoder used to transfrom values 'y'/'n' for Covid19 infection to values 1 and 0\n",
    "le = preprocessing.LabelEncoder()                \n",
    "le.fit([\"n\", \"y\"])\n",
    "\n",
    "# iterate over individuals represnted by network nodes indexed by nodeidx=0,1,...\n",
    "\n",
    "for nodeidx in range(nrnodes): \n",
    "    \n",
    "    # read in identifier of individual from list `uniquepart` and store in variable \"personid\"\n",
    "    personid = uniquepart[nodeidx]\n",
    "    \n",
    "    # create dataframe \"dmydf\" by selecting all rows from dataframe `df` with attribute `ID` equal to `personid`\n",
    "    dmydf = pd.DataFrame(df.loc[df['ID'] == personid].copy())\n",
    "    # create dataframe \"dmydf_features\" by selecting all rows from dataframe `df` with attribute `ID` equal to `personid`\n",
    "    dmydf_features = pd.DataFrame(df_features.loc[df_features['ID'] == personid].copy())\n",
    "    \n",
    "    # reset index of dataframe dmydf \n",
    "    dmydf.reset_index(drop=True, inplace=True) \n",
    "    # reset index of dataframe dmydf_features \n",
    "    dmydf_features.reset_index(drop=True, inplace=True) \n",
    "    \n",
    "    # read in latitude of first location recording in `dmydf` and store in variable `latitude`\n",
    "    latitude=dmydf.loc[0,['Lat']][0]\n",
    "    \n",
    "    # read in longitude of first location recording in `dmydf` and store in variable `longitude`\n",
    "    longitude=dmydf.loc[0,['Lon']][0]\n",
    "    \n",
    "    # read in Covid19 infection status of first location recording in `dmydf` and store in variable `valtmp`\n",
    "    valtmp=dmydf.loc[0,['Covid19']][0]\n",
    "    \n",
    "    # use le.transform() to map the infection status `valtmp` as `y`->1 and `n`-> 0\n",
    "    infected=le.transform([valtmp])\n",
    "    \n",
    "    # read in the date of the recording and store in variable date_tmp\n",
    "    date_tmp = dt.datetime.strptime(dmydf.loc[0,['Date']][0], '%d-%m-%Y').date() \n",
    "    \n",
    "    # read in the time of the recording and store in variable time_tmp\n",
    "    time_tmp = dt.datetime.strptime(dmydf.loc[0,['Time']][0], '%H:%M:%S').time()\n",
    "    \n",
    "    # combine date and time of location racording using `datetime.combine()\n",
    "    mydatetime = dt.datetime.combine(date_tmp, time_tmp)\n",
    "    \n",
    "    # add a node with index `nodeidx`\n",
    "    G.add_node(nodeidx)\n",
    "    # set the node attribute \"name\" to the string stored in \"personid\"\n",
    "    G.nodes[nodeidx]['name']= personid\n",
    "    # set the node attribute \"coords\" to a numpy array with entries \"latitude\" and \"longitude\"\n",
    "    G.nodes[nodeidx]['coords']= np.array([latitude,longitude])\n",
    "    # set the node attribute \"timestamp\" to the value of \"mydatetime\"\n",
    "    G.nodes[nodeidx]['timestamp'] = mydatetime\n",
    "    # set the node attribute \"y\" equal to 1 if individual has been reported as Covid-19 infected and 0 otherwise\n",
    "    G.nodes[nodeidx]['y'] = infected[0] \n",
    "    # set the node attribute \"w\" to a numpy array of shape (6,) and entries all zero\n",
    "    G.nodes[nodeidx]['w'] = np.zeros(nrfeatures)    \n",
    "    # set the node attribute \"b\" to 0.0\n",
    "    G.nodes[nodeidx]['b'] = 0.0  \n",
    "\n",
    "    # read in the features x1,...,x6 from dataframe \"dmydf_features\" and store in numpy array \"dmyvec\"\n",
    "    dmyvec = np.zeros(no_of_nodes)\n",
    "    for iterfeature in range(no_of_nodes):\n",
    "        keytmp = \"x%d\"% (iterfeature+1)\n",
    "        dmyvec[iterfeature]=dmydf_features.loc[0,[keytmp]][0]\n",
    "    \n",
    "    # set the node attribute \"x\" to the numpy array \"dmyvec\"\n",
    "    G.nodes[nodeidx]['x'] = dmyvec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67053978",
   "metadata": {},
   "outputs": [],
   "source": [
    "# two nested for-loops over node indices 0,1,...,nrnodes-1 \n",
    "# the loop variables are named \"nodeidx1\" and \"nodeidx2\"\n",
    "\n",
    "for nodeidx1 in range(nrnodes): \n",
    "    for nodeidx2 in range(nrnodes): \n",
    "        # test if nodeidx1 is different from nodeidx2\n",
    "        if nodeidx1!=nodeidx2 : \n",
    "            # compute the geodesic distance between individualas \"nodeidx1\" and \"nodeidx2\" in meters \n",
    "            nodedist=geodesic(G.nodes[nodeidx1]['coords'],G.nodes[nodeidx2]['coords']).meters\n",
    "            # if distance is below two meters connect invididuals by and edge. \n",
    "            if  nodedist<2: \n",
    "                G.add_edge(nodeidx1,nodeidx2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b9b7616",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new graph object \"SubGraph\" using G.subgraph() consisting of nodes 0,1,2,3,4\n",
    "SubGraph = G.subgraph([0,1,2,3,4])\n",
    "\n",
    "# read out node attribute `b`from all nodes in \"SubGraph\" and store in variable \"labels\"\n",
    "labels = nx.get_node_attributes(SubGraph, 'b') \n",
    "\n",
    "# plot \"SubGraph\" using nx.draw_networkx() with \"labels\" as node labels \n",
    "nx.draw_networkx(SubGraph,labels = labels) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "80b02c3f",
   "metadata": {},
   "source": [
    "Personalized Diagnosis"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "431890d5",
   "metadata": {},
   "source": [
    "his milestone requires you to learn personalized predictors for a Covid-19 infection. To this end you will the combine the gradient descent algorithm for logistic regression with a network averaging method for aggregating local gradients computed for each individual. \n",
    "\n",
    "More formally, we assign each invidiual $i$ a linear classifier with weight vector $\\mathbf{w}^{(i)}=\\big(w^{(i)}_{1},\\ldots,w^{(i)}_{6}\\big)^{T}$ and intercept (bias) term $b^{(i)}$. Given an individual $i$ with features $\\mathbf{x}^{(i)}$ (extracted from an audio recording) we diagnose a Covid-19 infection if $\\mathbf{w}^{T} \\mathbf{x}^{(i)} +b^{(i)} \\geq0$. To learn the weight vector and  intercept term for the node $i$ that belongs to the component $\\mathcal{C}$ of the contact network, we use a sufficient number of gradient descent steps\n",
    "$$ \\mathbf{w}^{(k+1)} = \\mathbf{w}^{(k)} - \\alpha \\mathbf{g}^{(k)} \\mbox{ with } \\mathbf{g}^{(k)}= (1/|\\mathcal{C}|) \\sum_{j \\in \\mathcal{C}} \\big(h\\big(\\big(\\mathbf{w}^{(k)}\\big)^{T} \\mathbf{x}^{(j)}\\big) - y^{(j)}\\big) \\mathbf{x}^{(j)} $$ \n",
    "and\n",
    "$$ b^{(k+1)} = b^{(k)} - \\alpha v^{(k)} \\mbox{ with } v^{(k)}= (1/|\\mathcal{C}|) \\sum_{j \\in \\mathcal{C}} \\big(h\\big(\\big(\\mathbf{w}^{(k)}\\big)^{T} \\mathbf{x}^{(j)}\\big) - y^{(j)}\\big)  $$. \n",
    "\n",
    "We will estimate the gradients $\\mathbf{g}^{(k)}$ and $v^{(k)}$ using the averaging algorithm that we used in Project 2 for computing the average infection rates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a82edc3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define sigmoid function\n",
    "# helps us computer the probability of an individual being infected\n",
    "# with Covid 19\n",
    "\n",
    "def sigmoid(X, theta):\n",
    "    '''\n",
    "    Computes the sigmoid of the linear combination of X and theta.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : numpy array of shape (n, m)\n",
    "\n",
    "    theta : numpy array of shape (m,)\n",
    "        The parameters of the logistic regression model.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    numpy array of shape (n,)\n",
    "        The sigmoid of the linear combination of X and theta.\n",
    "    \n",
    "    Examples\n",
    "    --------\n",
    "    >>> X = np.array([[1, 2, 3], [4, 5, 6]])\n",
    "    >>> theta = np.array([1, 2, 3])\n",
    "    >>> sigmoid(X, theta)\n",
    "    array([0.99987661, 1.        ])\n",
    "    '''\n",
    "    # compute the linear combination of x and theta\n",
    "    z = np.dot(X, theta[1:]) + theta[0]\n",
    "\n",
    "    # compute the sigmoid of z\n",
    "    return 1 / (1 + np.exp(-z))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19b8aaf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# maps each node to a dictionary of its neighbors\n",
    "weights_tmp_dic=nx.get_node_attributes(G,'w')\n",
    "\n",
    "# make zeros based on the number of nodes and features\n",
    "weights_tmp = np.zeros((nrnodes,nrfeatures))\n",
    "\n",
    "# maps each node to an intercept value\n",
    "intercept_tmp_dic=nx.get_node_attributes(G,'b')\n",
    "\n",
    "# maps zero based on the number of nodes\n",
    "intercept_tmp = np.zeros(nrnodes)\n",
    "\n",
    "# maps each node to a feature vector\n",
    "features_tmp_dic=nx.get_node_attributes(G,'x')\n",
    "\n",
    "# make zeros based on the number of nodes and features\n",
    "features_tmp = np.zeros((nrnodes,nrfeatures))\n",
    "\n",
    "# maps each node to a label\n",
    "label_tmp_dic=nx.get_node_attributes(G,'y')\n",
    "\n",
    "# maps zero based on the number of nodes\n",
    "label_tmp = np.zeros(nrnodes)\n",
    "\n",
    "# loop over all nodes\n",
    "for iternode in range(nrnodes):\n",
    "      weights_tmp[iternode,:] = weights_tmp_dic[iternode]\n",
    "      intercept_tmp[iternode] = intercept_tmp_dic[iternode]\n",
    "      features_tmp[iternode,:] = features_tmp_dic[iternode]\n",
    "      label_tmp[iternode] = label_tmp_dic[iternode]\n",
    "\n",
    "# set step-size\n",
    "alpha = 1/10\n",
    "    \n",
    "weights_old = weights_tmp.copy() \n",
    "intercept_old = intercept_tmp.copy()\n",
    "gradient_tmp = np.zeros((nrnodes,nrfeatures+1)) # each row hold the gradient for intercept and weights \n",
    "gradient_old = np.zeros((nrnodes,nrfeatures+1))\n",
    "\n",
    "nriters=50\n",
    "\n",
    "# create \"Metropolis-Hastings\" weights and store them in numpy array `W_MH`\n",
    "W_MH = np.zeros((nrnodes,nrnodes)) # create array for MH weights and init to all zeroes\n",
    "# iterate over all edges in the contact network G\n",
    "for edge in G.edges(): \n",
    "    node_a = edge[0]\n",
    "    node_b = edge[1]\n",
    "    W_MH[node_a,node_b] = 1/(np.max([G.degree(node_a),G.degree(node_b)])+1)\n",
    "    W_MH[node_b,node_a] = 1/(np.max([G.degree(node_a),G.degree(node_b)])+1)\n",
    "\n",
    "# loop over all nodes in the contact network G\n",
    "for nodedmy in G.nodes(): \n",
    "# set weights W[nodedmy,nodedmy] to 1 - sum of weights for all neighbors of nodedmy\n",
    "    W_MH[nodedmy,nodedmy] = 1-np.sum(W_MH[nodedmy,:])\n",
    "    \n",
    "# set number of iterations for gradient descent to default value 200\n",
    "nrlogregiters = 10\n",
    "\n",
    "# main loop for the federated learning algorithm \n",
    "# each iteration amounts to network averaging of all local gradients \n",
    "\n",
    "for iterlogreg in range(nrlogregiters):\n",
    "# compute gradients at each node \n",
    "    for iternode in range(nrnodes):\n",
    "# stack weights and intercept into theta\n",
    "        theta = np.hstack((intercept_tmp[iternode],weights_tmp[iternode]))\n",
    "        # compute sgmoid function of predictor value w^T x\n",
    "        hx = sigmoid(features_tmp[iternode], theta)\n",
    "        # calculate error\n",
    "        error = hx - label_tmp[iternode]\n",
    "        # compute gradient for local loss function and store in gradient_tmp\n",
    "        gradient_tmp[iternode,:] = np.hstack((error,error*features_tmp[iternode]))\n",
    "          \n",
    "    \n",
    "    \n",
    "# average gradients using nriters consensus iterations\n",
    "    for iterdmy in range(nriters):\n",
    "        # read in current values of \"Rate\" attributes into numpy array `graphsigold`\n",
    "        gradient_old = gradient_tmp \n",
    "        # update estimate \"gradient_tmp\" by applying W_MH to current estimate\n",
    "        gradient_tmp = np.dot(W_MH, gradient_old)\n",
    "    \n",
    "    # do a gradient descent step for intercept_tmp using step size alpha\n",
    "    intercept_tmp -= alpha*gradient_tmp[:,0]\n",
    "    # do a gradient descent step for weights_tmp using step size alpha\n",
    "    weights_tmp -= alpha*gradient_tmp[:,1:]\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "# loop over all nodes in the contact network G store the weights in \"weights_tmp\" in the node attribute \"weights\"\n",
    "# store the incepts in \"intercept_tmp\" in the node attribute \"intercep\"\n",
    "\n",
    "for node_i in G.nodes(data=False): \n",
    "    G.node[node_i]['w'] = weights_tmp[node_i]\n",
    "    G.node[node_i]['b'] = intercept_tmp[node_i]\n",
    "  \n",
    "    print(\"weights node %d :\"%node_i,weights_tmp[node_i])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "a6515246a4d677b32bcae4f85f074a2a28abed2fb888ef87af1449dc43f51527"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
